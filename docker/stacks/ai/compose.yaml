services:
  ollama:
    container_name: ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      TZ: "Europe/London"
      OLLAMA_ORIGINS: "*"
      DISABLED_OLLAMA_KEEP_ALIVE: "15m"
      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
      NVIDIA_VISIBLE_DEVICES: "all"
      OLLAMA_HOST: "0.0.0.0:11434"
    expose:
      - 11434/tcp
    image: ollama/ollama:0.9.6
    labels:
      net.unraid.docker.icon: https://ollama.ai/public/ollama.png
      net.unraid.docker.managed: komodo
      net.unraid.docker.webui: http://[IP]:[PORT:11434]/
    networks:
      - f9-nas
    volumes:
      - /mnt/ai/ai-appdata/ollama:/root/.ollama
  
  open-webui:
    container_name: open-webui
    environment:
      OLLAMA_BASE_URL: "http://ollama:11434"
      OAUTH_CLIENT_ID: "ncLdk8QQPrzCCBUWI6jE8HO3UKOU5whFb5qlHsOX"
      OAUTH_CLIENT_SECRET: "${OPEN_WEBUI_OAUTH_CLIENT_SECRET}"
      OAUTH_PROVIDER_NAME: "F9Casa"
      OPENID_PROVIDER_URL: "https://auth.f9.casa/application/o/open-webui/.well-known/openid-configuration"
      TZ: "Europe/London"
      ENABLE_OAUTH_SIGNUP: "true"
      OAUTH_MERGE_ACCOUNTS_BY_EMAIL: "true"
      ENV: "prod"
      PORT: "8080"
      USE_OLLAMA_DOCKER: "false"
      USE_CUDA_DOCKER: "false"
      USE_CUDA_DOCKER_VER: "cu121"
      USE_EMBEDDING_MODEL_DOCKER: "sentence-transformers/all-MiniLM-L6-v2"
      USE_RERANKING_MODEL_DOCKER: ""
      SCARF_NO_ANALYTICS: "true"
      DO_NOT_TRACK: "true"
      WHISPER_MODEL: "base"
      WHISPER_MODEL_DIR: "/app/backend/data/cache/whisper/models"
      RAG_EMBEDDING_MODEL: "sentence-transformers/all-MiniLM-L6-v2"
      RAG_RERANKING_MODEL: ""
      SENTENCE_TRANSFORMERS_HOME: "/app/backend/data/cache/embedding/models"
      TIKTOKEN_ENCODING_NAME: "cl100k_base"
      TIKTOKEN_CACHE_DIR: "/app/backend/data/cache/tiktoken"
      DOCKER: "true"
    image: ghcr.io/open-webui/open-webui:v0.6.15
    labels:
      net.unraid.docker.icon: https://raw.githubusercontent.com/open-webui/open-webui/main/static/favicon.png
      net.unraid.docker.managed: komodo
      net.unraid.docker.webui: http://[IP]:[PORT:8080]/
    networks:
      - f9-nas
    ports:
      - 8480:8080/tcp
    volumes:
      - /mnt/ai/ai-appdata/ollama-webui:/app/backend/data

  stable-diffusion:
    container_name: stable-diffusion
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      TZ: "Europe/London"
      WEBUI_VERSION: "02.forge"
      NVIDIA_VISIBLE_DEVICES: "GPU-0b26890d-e635-4498-fa3e-4e7c59872681"
      PUID: "99"
      PGID: "100"
      NVIDIA_DRIVER_CAPABILITIES: "all"
    image: holaflenain/stable-diffusion:3.4.0
    labels:
      net.unraid.docker.icon: https://github.com/superboki/ressources/blob/6e39a0d104bf2c2de286743bf60b46134c3f043d/stable-diffusion-advanced/stable-diffusion-advanced.png?raw=true
      net.unraid.docker.managed: komodo
      net.unraid.docker.webui: http://[IP]:[PORT:9000]
    networks:
      - f9-nas
    ports:
      - 7400:9000/tcp
    volumes:
      - /mnt/ai/ai-appdata/stable-diffusion:/config

networks: 
  f9-nas:
    external: true
    name: f9-nas