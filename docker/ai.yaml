services:
  ollama:
    container_name: ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
        limits:
          memory: 4G
    environment:
      TZ: "Europe/London"
      OLLAMA_ORIGINS: "*"
      DISABLED_OLLAMA_KEEP_ALIVE: "15m"
      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
      NVIDIA_VISIBLE_DEVICES: "all"
      OLLAMA_HOST: "0.0.0.0:11434"
    ports:
      - 11434:11434/tcp
    image: ollama/ollama:0.11.6
    volumes:
      - /mnt/AI/appdata/ollama:/root/.ollama

  stable-diffusion:
    container_name: stable-diffusion
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
        limits:
          memory: 4G
    environment:
      TZ: "Europe/London"
      WEBUI_VERSION: "07"
      NVIDIA_VISIBLE_DEVICES: "ALL"
      PUID: "99"
      PGID: "100"
      NVIDIA_DRIVER_CAPABILITIES: "all"
    image: holaflenain/stable-diffusion:3.5.1
    ports:
      - 7400:9000/tcp
    volumes:
      - /mnt/AI/appdata/stable-diffusion:/config

  immich-machine-learning:
    container_name: immich_machine_learning
    image: ghcr.io/immich-app/immich-machine-learning:release-cuda
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
        limits:
          memory: 4G
    volumes:
      - /mnt/AI/appdata/immich-machine-learning/cache:/cache
    ports:
      - 3003:3003
